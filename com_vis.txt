import cv2
import numpy as np
from PIL import Image
import os
import cx_Oracle
import pyttsx3

con=cx_Oracle.connect('SYSTEM/265393@localhost')
cur=con.cursor()




listdata =list(cur.execute("select * from comp_vis"))
id=len(listdata)
def create_db():
    engine = pyttsx3.init()
    engine.setProperty("rate",200)
    #face_cascade = cv2.CascadeClassifier('F:/Program Files/opencv/sources/data/haarcascades/haarcascade_frontalface_default.xml')
    face_cascade = cv2.CascadeClassifier('C:/pro_/face/haarcascade_frontalface_default.xml')
    global listdata
    cap = cv2.VideoCapture(0)
    global id
    id=len(listdata)
    id+=1
    l=[]
    l.append(id)
    
    engine.say("Please enter your name.")
    engine.runAndWait()
    
    l.append(input('Name:'))

    engine.say("Please enter your registration number.")
    engine.runAndWait()
    
    l.append(input('Registration number:'))

    engine.say("Taking pictures in a few moments, please look into the camera.")
    engine.runAndWait()
    sql="insert into comp_vis values(%d,'%s','%s')"%(id,l[1],l[2])
    cur.execute(sql)
    con.commit()
    listdata.append(l)
    sampleN=0;
    
    while 1:
        
        ret, img = cap.read()
        
        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
        
        faces = face_cascade.detectMultiScale(gray, 1.3, 5)
        
        for (x,y,w,h) in faces:
            
            sampleN=sampleN+1;
            
            cv2.imwrite("C:/pro_/faces/faces."+str(id)+ "." +str(sampleN)+ ".jpg", gray[y:y+h, x:x+w])
            
            cv2.rectangle(img,(x,y),(x+w,y+h),(255,0,0),2)
            
            cv2.waitKey(100)
            
            cv2.imshow('img',img)
            
            cv2.waitKey(1)

        if sampleN > 200:

            break

    cap.release()
    
    cv2.destroyAllWindows()

# Path for face image database
path = 'C:/pro_/faces'

recognizer = cv2.face.LBPHFaceRecognizer_create()
detector = cv2.CascadeClassifier("C:/pro_/face/haarcascade_frontalface_default.xml");

# function to get the images and label data
def getImagesAndLabels(path):

    imagePaths = [os.path.join(path,f) for f in os.listdir(path)]     
    faceSamples=[]
    ids = []

    for imagePath in imagePaths:

        PIL_img = Image.open(imagePath).convert('L') # convert it to grayscale
        img_numpy = np.array(PIL_img,'uint8')

        id = int(os.path.split(imagePath)[-1].split(".")[1])
        faces = detector.detectMultiScale(img_numpy)

        for (x,y,w,h) in faces:
            faceSamples.append(img_numpy[y:y+h,x:x+w])
            ids.append(id)

    return faceSamples,ids

def train():

    print ("\n [INFO] Training faces. It will take a few seconds. Wait ...")
    faces,ids = getImagesAndLabels(path)
    recognizer.train(faces, np.array(ids))
    
    # Save the model into trainer/trainer.yml
    recognizer.write('C:/pro_/trash.yml') # recognizer.save() worked on Mac, but not on Pi
    
    # Print the numer of faces trained and end program
    print("\n [INFO] {0} faces trained. Exiting Program".format(len(np.unique(ids))))
        
    
def see():
    global listdata
    recognizer = cv2.face.LBPHFaceRecognizer_create()
    recognizer.read('C:/pro_/trash.yml')
    cascadePath = "C:/pro_/face/haarcascade_frontalface_default.xml"
    faceCascade = cv2.CascadeClassifier(cascadePath);
    
    font = cv2.FONT_HERSHEY_SIMPLEX
    
    #iniciate id counter
    id = 0
    
    # names related to ids: example ==> Marcelo: id=1,  etc
    #names = ['None', 'Marcelo', 'Paula', 'Ilza', 'Z', 'W','nithu','nithu'] 
    #names = ['none','dheeraj','ravi','nithish','karthik']
    # Initialize and start realtime video capture
    cam = cv2.VideoCapture(0)
    cam.set(3, 640) # set video widht
    cam.set(4, 480) # set video height
    
    # Define min window size to be recognized as a face
    minW = 0.1*cam.get(3)
    minH = 0.1*cam.get(4)
    c=0
    c1=0
    x1=0
    while True:
        
        ret, img =cam.read()
        #img = cv2.flip(img, -1) # Flip vertically
        
        gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)
        
        faces = faceCascade.detectMultiScale( 
                gray, 
                scaleFactor = 1.2,
                minNeighbors = 5,
                minSize = (int(minW), int(minH)),
                )

        for(x,y,w,h) in faces:
            
            cv2.rectangle(img, (x,y), (x+w,y+h), (0,255,0), 2)
            
            id, confidence = recognizer.predict(gray[y:y+h,x:x+w])
            # Check if confidence is less them 100 ==> "0" is perfect match 
            if (0 < confidence < 50 and id!=0):
                m=id
                id=(listdata[id-1][1])
                print(id)
                confidence = "  {0}%".format(round(100 - confidence))
                c=0
                print(m,'---',x1,'--',c1)
                if(m==x1):
                    c1+=1
                else:
                    c1=0
                    x1=m
                if(c1==1):
                    engine = pyttsx3.init()
                    engine.setProperty("rate",200)
                    engine.say("Hey"+listdata[m-1][1])
                    engine.runAndWait()
            else:
                c+=1
                id = "unknown"
                confidence = "  {0}%".format(round(100 - confidence))
            if(c==100):
                cam.release()
                cv2.destroyAllWindows()
                engine = pyttsx3.init()
                engine.setProperty("rate",200)
                engine.say("Do you want me to remember you?")
                engine.runAndWait()
                j=input("Do you want me to remember you? [y/n] ")

                if(j=='y' or j=='Y' or j=='Yes' or j=='YES' or j=='yes'):

                    create_db()
                    engine = pyttsx3.init()
                    engine.setProperty("rate",200)
                    engine.say("Training Data, I am almost ready.")
                    engine.runAndWait()
                    train()
                    listdata =list(cur.execute("select * from comp_vis"))
                    engine.say("Nice to meet you"+listdata[len(listdata)-1][1])
                    engine.runAndWait()
                c=0
                see()
            print(str(id))
            cv2.putText(img, str(id), (x+5,y-5), font, 1, (255,255,255), 2)
            cv2.putText(img, str(confidence), (x+5,y+h-5), font, 1, (255,255,0), 1)  
    
        cv2.imshow('camera',img) 

        k = cv2.waitKey(10) & 0xff # Press 'ESC' for exiting video
        k=k+10
        if k == 27:
            break
        

    # Do a bit of cleanup
    print("\n [INFO] Exiting Program and cleanup stuff")
    cam.release()
    cv2.destroyAllWindows()

print(listdata)

while 1:
    
    see()